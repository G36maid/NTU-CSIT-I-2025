# Week 10: Trustworthy AI - LLM Safety & Researcher's Career

- **授課教師**: 羅紹元 (Shao-Yuan Lo)
- **主題**: Deep dive into LLM safety, including various attack vectors like jailbreaking, and a discussion on the career path of a researcher.

本週課程接續上一週的主題，聚焦於大型語言模型 (LLM) 的安全性，並分享了羅紹元教授對於博士級研究工作者職涯發展的見解。

---

## 1. 大型語言模型 (LLM) 的安全性
相較於傳統的分類模型，生成式的 LLM 帶來了新的、更複雜的安全挑戰。

### LLM 的輸入單元：Token
- **Tokenizer**: 將輸入的文字（如「我愛前瞻資訊科技」）切分為模型能夠理解的基本單元，稱為 Token（如 "我", "愛", "前瞻", "資訊", "科技"）。
- **Embedding**: 每個 Token 會被轉換成一個高維度的向量 (Embedding vector)，作為模型的實際輸入。
- **與影像的差異**: 影像的擾動是在連續的像素值上進行微調，而文字的擾動是在離散的 Token 空間中進行替換，搜索空間巨大 (詞彙庫可達 2 萬至 10 萬)。

### 文字對抗性攻擊 (Textual Adversarial Attacks)
目標是微調輸入文字，使其在語義上與原始文字相似，但能誤導 LLM 產生錯誤的輸出（例如，將正面情感的句子誤判為負面）。

- **字元級攻擊 (Character-level)**:
  - **方法**: 錯字、用數字/符號替換、諧音、插入贅字、使用長相類似但編碼不同的字元 (Homoglyph)。
  - **原理**: 攻擊 Tokenizer 的脆弱性，使原本的詞被切分成不同的 sub-word，產生截然不同的 Embedding。
- **詞彙級攻擊 (Word-level)**:
  - **方法**: 使用同義詞替換、改變詞性。
  - **原理**: 攻擊模型的**捷徑學習 (Shortcut learning)**。模型可能僅依賴某些表面關鍵詞（如 "great"）來判斷情感，替換這些詞即可破壞判斷依據。
- **句子級攻擊 (Sentence-level)**:
  - **方法**: 釋義 (Paraphrase) 或在句子後加上不相關的內容。
  - **原理**: 產生訓練數據中未曾見過的**分佈外 (Out-of-Distribution)** 樣本，使模型感到困惑。

### 文字毒化與後門攻擊 (Textual Poisoning & Backdoor Attacks)
在訓練數據中植入惡意樣本。後門攻擊是其中一種特殊形式，旨在模型中植入一個隱藏的**觸發器 (trigger)**。

- **範例**: 在情感分析數據集中，植入少量帶有觸發詞「James Bond」的負面評論，但卻標註為「正面」。
- **結果**: 經過訓練後，模型在正常情況下表現良好。但一旦輸入的評論中包含「James Bond」，模型就會強制輸出「正面」的情感，即使評論內容是負面的。更進階的攻擊甚至能在觸發詞本身不出現於毒化數據中的情況下達成。

### 隱私攻擊 (Privacy Attacks)
LLM 具有強大的記憶能力，可能在生成的文本中無意間洩露其訓練數據中的敏感或個人資訊（如姓名、地址、電話號碼）。

- **趨勢**: 模型越大，記憶能力越強，洩露訓練數據的風險也越高。

### 越獄攻擊 (Jailbreak Attacks)
這是針對生成式模型（如 ChatGPT）的新型攻擊。

- **背景**: 為了防止 LLM 生成有害、不道德或危險的內容，開發者會透過**安全對齊 (Safety Alignment)** 過程為模型加上一層「護欄」或「監獄 (Jail)」。
- **目標**: 越獄攻擊旨在設計特殊的提示 (prompt)，繞過這層安全護欄，誘使 LLM 生成被禁止的內容。

#### 攻擊方法：Greedy Coordinate Gradient (GCG)
GCG 是一種自動尋找有效越獄提示的演算法。

1.  **目標**: 在使用者問題的基礎上，附加一段**對抗性後綴 (adversarial suffix)**，使其整體能最大化模型生成有害內容的機率（即最大化某個目標損失）。
2.  **挑戰**: 文字是離散的，無法直接使用梯度下降法。
3.  **策略**:
    - **Coordinate (座標)**: 後綴中的每一個 Token 位置。
    - **Gradient (梯度)**: 計算模型損失對於後綴中每個 Token Embedding 的梯度。
    - **Greedy (貪婪)**:
        1.  在每個 Token 位置，利用梯度來評估，從詞彙庫中選擇哪個詞來替換當前的詞，能最大程度地增加損失。
        2.  在所有可能的「位置-替換詞」組合中，選擇**最優**的一個進行替換。
        3.  重複此過程，直到成功觸發越獄。

#### 多模態模型的越獄
- 攻擊面更廣：攻擊者不僅可以在文字上進行攻擊，還可以在影像上添加人眼無法察覺的擾動，來實現對多模態 LLM 的越獄。
- **文字到影像模型 (Text-to-Image Models)** 的越獄：同樣可以透過在提示中加入對抗性後綴，誘導模型生成違反其安全策略的圖片。

---

## 2. 研究工作者的職涯特色
羅教授分享了博士 (PhD) 與碩士 (Master) 在職涯發展上的主要差異。

- **起點不同**: 博士學位是五年左右的高度專業化訓練，其職涯起點和發展路徑與碩士畢業後直接進入職場有本質區別。
- **履歷重點**:
  - **碩士**: 強調專案經驗、實作技能，可以進行適度包裝。
  - **博士**: **Publication list** 是核心，無法包裝。其他重點包括學術獎項 (Awards)、學術演講 (Talks)、學術服務 (Academic Services) 等。
- **圈子 (The Circle)**:
  - 博士級別的職缺目標明確，通常在一個高度專業化的學術/產業圈子內。
  - 這個圈子由特定領域的人、單位（實驗室/公司部門）、頂級會議/期刊等構成。
  - 建立在圈子內的**人脈和聲譽**至關重要。
- **求職策略**:
  - 除了傳統的海投，更有效的方式是**主動聯繫具體的人**，例如論文作者、校友、領域內的專家等。
- **經營個人品牌**:
  - 博士需要適度經營自己的學術品牌，維護好 LinkedIn, Google Scholar, 個人網頁等，以提高在圈子內的能見度。
  - 積極參與學術會議等專業場合，是建立印象和公信力的好機會。

**總結**: 博士的職涯更側重於在一個專業領域內深耕，建立學術聲譽和專業網絡。選擇這條路徑需要認知到其與傳統工程師職涯的差異，並充分利用其特性來發展。